name: Run Spark Unit Tests

on:
  push:
    branches: [ "main", "develop" ]
    paths:
      - 'spark_df_utils/**'
      - 'tests/**'
      - 'requirements*.txt'
      - 'setup.py'
      - '.github/workflows/test.yml'
  pull_request:
    branches: [ "main", "develop" ]
    paths:
      - 'spark_df_utils/**'
      - 'tests/**'
      - 'requirements*.txt'
      - 'setup.py'
      - '.github/workflows/test.yml'

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python 
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"

    - name: Set up Java 11
      uses: actions/setup-java@v3
      with:
        distribution: "temurin"
        java-version: "11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 pyspark pytest
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

    - name: Lint with flake8
      run: |
        pip install flake8
        # stop the build if there are Python syntax errors or undefined names
        flake8 spark_df_utils tests --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings
        flake8 spark_df_utils tests --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    # - name: Run unit tests with pytest
    #  run: |
    #    pytest tests/ -v --cov=spark_df_utils --cov-report=xml --cov-report=html --cov-report=term-missing

